{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Image Processing\n",
    "\n",
    "Denoising and deblurring with some classical methods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo for classical method\n",
    "- median filter;\n",
    "- bilateral filter;\n",
    "- wiener filter;\n",
    "- wavelet transform (dummy approach);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the path of the project to the system path\n",
    "import os\n",
    "import sys\n",
    "path = os.getcwd()\n",
    "sys.path.append(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for different noise vs method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using stage1_code\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempted relative import beyond top-level package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/vanple/Desktop/ucla/_Courses_/3D-vis-reasoning/stage1/demo.ipynb Cell 5\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vanple/Desktop/ucla/_Courses_/3D-vis-reasoning/stage1/demo.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstage1_test\u001b[39;00m \u001b[39mimport\u001b[39;00m test_dummy_stage1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vanple/Desktop/ucla/_Courses_/3D-vis-reasoning/stage1/demo.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vanple/Desktop/ucla/_Courses_/3D-vis-reasoning/stage1/demo.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m noise \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mgaussian_blur\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msp_noise\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgaussian_blur\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mspeckle_noise\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmotion_blur\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/ucla/_Courses_/3D-vis-reasoning/stage1/src/stage1_test.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_dummy_stage1\u001b[39m(noise_type: \u001b[39mstr\u001b[39m, method:\u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[1;32m     14\u001b[0m     \u001b[39m\"\"\" \u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m        dummy test for stage 1 noise images with data provided by the course\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m        return: a list of psnr and ssim values\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ucla/_Courses_/3D-vis-reasoning/stage1/src/utils.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnatsort\u001b[39;00m \u001b[39mimport\u001b[39;00m natsorted\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mglob\u001b[39;00m \u001b[39mimport\u001b[39;00m glob\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdenoise\u001b[39;00m \u001b[39mimport\u001b[39;00m DenoiseSolver\n\u001b[1;32m      8\u001b[0m \u001b[39m# load dummy images from a folder\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_dummy\u001b[39m(noise_type: \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/ucla/_Courses_/3D-vis-reasoning/stage1/src/denoise.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmorphology\u001b[39;00m \u001b[39mimport\u001b[39;00m disk\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpywt\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mref\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mblind_deconv\u001b[39;00m \u001b[39mimport\u001b[39;00m blind_deconv\n\u001b[1;32m      8\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDenoiseSolver\u001b[39;00m():\n\u001b[1;32m      9\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m    Denoise with 2D Spatial or Frequential Filters:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: attempted relative import beyond top-level package"
     ]
    }
   ],
   "source": [
    "from src.stage1_test import test_dummy_stage1\n",
    "import pandas as pd\n",
    "\n",
    "noise = ['gaussian_blur', 'sp_noise', 'gaussian_blur', 'speckle_noise','motion_blur']\n",
    "method = ['median', 'bilateral', 'wiener', 'wavelet']\n",
    "stats = pd.DataFrame(columns=['noise_type', 'method', 'psnr', 'ssim'])\n",
    "\n",
    "for n in noise:\n",
    "    for m in method:\n",
    "        stat = test_dummy_stage1(n, m)\n",
    "        stats = stats.append(pd.Series(stat, index=stats.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Motion blur kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "from src.utils import load_images\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = np.arange(3, 21, 1)  # adjust as needed\n",
    "angle = np.arange(0, 360, 0.5)  # adjust as needed\n",
    "\n",
    "best_psnr = 0\n",
    "best_ssim = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_images(path+'/stage1_data/input_imgs')\n",
    "image = np.array(ImageOps.grayscale(Image.open(next(images))))/255.0\n",
    "\n",
    "ref_images  = load_images(path+'/stage1_data/motion_blur')\n",
    "ref_image = np.array(ImageOps.grayscale(Image.open(next(ref_images))))/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the motion blur kernel\n",
    "for ks in kernel_size:\n",
    "    for a in angle:\n",
    "        motion_blur_kernel = np.zeros((ks, ks))\n",
    "        motion_blur_kernel[int((ks-1)/2), :] = np.ones(ks)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D((int((ks-1)/2), int((ks-1)/2)), a, 1)\n",
    "        motion_blur_kernel = cv2.warpAffine(motion_blur_kernel, rotation_matrix, (ks, ks))\n",
    "        # Normalize the kernel\n",
    "        motion_blur_kernel /= motion_blur_kernel.sum()\n",
    "        # Apply the kernel to the input image\n",
    "        image_blurred = convolve2d(image, motion_blur_kernel, mode='same', boundary='symm')\n",
    "        # compute psnr and ssim\n",
    "        psnr_value = psnr(image, image_blurred)\n",
    "        ssim_value = ssim(image, image_blurred, multichannel=True, data_range=image_blurred.max() - image_blurred.min())\n",
    "        if psnr_value > best_psnr:\n",
    "            best_psnr = psnr_value\n",
    "            best_ssim = ssim_value\n",
    "            best_kernel = motion_blur_kernel\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
